{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import flipkart\n",
    "\n",
    "chrome_browser = webdriver.Chrome('C:/Users/Admin/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "\n",
    "print('Enter 1 if you want to search for Book,Enter 2 if you want to search for Electronics:: ', end='')\n",
    "choice = int(input())\n",
    "\n",
    "print('What do you want to search for ? : ', end='')\n",
    "query_string = input()\n",
    "url = 'https://www.amazon.in/s?k=' + query_string + '&page='\n",
    "\n",
    "print('What keyword do you want apply for? : ')\n",
    "print('If you want to apply more than one keyword then use | between words,like below example,')\n",
    "print('Suppose I 3 keywords, \"xy\",\"ab\",\"he llo\" then,give input like this: xy|ab|he llo')\n",
    "keyword = input()\n",
    "flipkart_product_name, flipkart_price, flipkart_links = flipkart.check_for_flipkart(choice, query_string, keyword)\n",
    "\n",
    "product_name = []\n",
    "price_list = []\n",
    "link_list = []\n",
    "for i, j, k in zip(flipkart_product_name, flipkart_price, flipkart_links):\n",
    "    print(f'{i} @ {j}\\n')\n",
    "    product_name.append(i)\n",
    "    price_list.append(j)\n",
    "    link_list.append(k)\n",
    "\n",
    "j = 0\n",
    "count = 0\n",
    "for i in range(3):\n",
    "\n",
    "    url1 = \"\"\n",
    "    url1 = url + str(i)\n",
    "    chrome_browser.get(url1)\n",
    "\n",
    "    element = chrome_browser.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")  # product name\n",
    "    # rating =chrome_browser.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "    # gives total number of persons who have give their ratings\n",
    "\n",
    "    for_accurate_price = chrome_browser.find_elements_by_css_selector('.s-no-outline')\n",
    "\n",
    "    for m in for_accurate_price:\n",
    "        link_list.append(m.get_attribute('href'))\n",
    "        count += 1\n",
    "\n",
    "    for ele in element:\n",
    "        # print(f'{j} Page no.{i}. {ele.text}')\n",
    "        product_name.append(ele.text)\n",
    "        # price_list.append(pricee.text)\n",
    "        # print()\n",
    "        j += 1\n",
    "\n",
    "print(f'len(link_list) = {len(link_list)},  len(product_name) = {len(product_name)}')\n",
    "\n",
    "# for i in link_list:\n",
    "#     print(i)\n",
    "\n",
    "count = 0\n",
    "file_product_name = []\n",
    "file_link_list = []\n",
    "\n",
    "if choice == 2:\n",
    "    for (name, link) in zip(product_name, link_list):\n",
    "        chrome_browser.get(link)\n",
    "        try:\n",
    "            element = chrome_browser.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    "            price = chrome_browser.find_element_by_xpath(\"//span[@id='priceblock_ourprice']\")  # product name\n",
    "            if re.search(keyword, element.text, re.IGNORECASE):\n",
    "                file_product_name.append(element.text)\n",
    "                price_list.append(price.text)\n",
    "                file_link_list.append(link)\n",
    "        except Exception:\n",
    "            try:\n",
    "                price = chrome_browser.find_element_by_xpath(\"//span[@id='priceblock_saleprice']\")\n",
    "                if re.search(keyword, element.text, re.IGNORECASE):\n",
    "                    file_product_name.append(element.text)\n",
    "                    price_list.append(price.text)\n",
    "                    file_link_list.append(link)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    price = chrome_browser.find_element_by_xpath(\"//span[@id='priceblock_dealprice']\")\n",
    "                    if re.search(keyword, element.text, re.IGNORECASE):\n",
    "                        file_product_name.append(element.text)\n",
    "                        price_list.append(price.text)\n",
    "                        file_link_list.append(link)\n",
    "                except Exception:\n",
    "                    count += 1\n",
    "elif choice == 1:\n",
    "    for (name, link) in zip(product_name, link_list):\n",
    "        chrome_browser.get(link)\n",
    "        try:\n",
    "            element = chrome_browser.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    "            price = chrome_browser.find_element_by_xpath(\"//span[@class='a-size-base a-color-price a-color-price']\")  # product name\n",
    "            if re.search(keyword, element.text, re.IGNORECASE):\n",
    "                file_product_name.append(element.text)\n",
    "                price_list.append(price.text)\n",
    "                file_link_list.append(link)\n",
    "        except Exception:\n",
    "            count += 1\n",
    "\n",
    "print(f'exception count = {count}')\n",
    "print(f'len(file_product_name) = {len(file_product_name)}, len(price_list) = {len(price_list)}')\n",
    "\n",
    "for (i, j) in zip(file_product_name, price_list):\n",
    "    print('{} @{}\\n'.format(i, j))\n",
    "\n",
    "\n",
    "file = pd.DataFrame({'Product Name': file_product_name,\n",
    "                    'Link': file_link_list,\n",
    "                     'Price': price_list})\n",
    "\n",
    "file['Price'] = file['Price'].str.replace('[\\â‚¹\\,\\.]','').astype(int)  #to remove Rupee sign from this Price column and to make it as int\n",
    "file['Price'] = file['Price']/100\n",
    "\n",
    "fig , ax = plt.subplots(figsize=(10,7))\n",
    "ax.scatter(file['Product Name'],file['Price'])\n",
    "crs = mplcursors.cursor(ax,hover=True)\n",
    "crs.connect(\"add\", lambda sel: sel.annotation.set_text('Point {},{}'.format(sel.target[0]+3, sel.target[1])))\n",
    "\n",
    "# plt.xticks(file['Product Name'],\"\")  # this will remove x-axis labels from the plot\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "file.to_csv('Amazon.csv', index=False)\n",
    "\n",
    "plt.show();\n",
    "\n",
    "print('Provide a link,for which would you like to analyze comment :: ')\n",
    "chosen_link = input()\n",
    "boolean = True\n",
    "comment_list = []\n",
    "page_index = 1\n",
    "if 'flipkart' in chosen_link:\n",
    "    comment_list = flipkart.check_for_flipkart_comment(chosen_link)\n",
    "\n",
    "else:\n",
    "\n",
    "    while boolean:\n",
    "        url = chosen_link + '&pageNumber=' + str(page_index)\n",
    "        try:\n",
    "            chrome_browser.get(url)\n",
    "            comments = chrome_browser.find_elements_by_xpath(\"//span[@data-hook='review-body']\")\n",
    "            page_index += 1\n",
    "            for i in comments:\n",
    "                print(i.text)\n",
    "                print()\n",
    "                if i.text in comment_list:\n",
    "                    break\n",
    "                comment_list.append(i.text)\n",
    "        except Exception:\n",
    "            boolean = False\n",
    "        if page_index > 75:\n",
    "            boolean = False\n",
    "file2 = pd.DataFrame()\n",
    "file2['Comments'] = comment_list\n",
    "file2.to_csv('Comment.csv', index=False)\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiment = []\n",
    "sentiment_for_graph = {'pos':0,'neg':0,'neutral':0}\n",
    "file = pd.read_csv('Comment.csv')\n",
    "for i in file['Comments']:\n",
    "    b = sid.polarity_scores(i)\n",
    "    if b['compound']>=0.05:\n",
    "        sentiment.append('pos')\n",
    "        sentiment_for_graph['pos']+=1\n",
    "    elif -0.05 < b['compound'] < 0.05:\n",
    "        sentiment.append('neutral')\n",
    "        sentiment_for_graph['neutral']+=1\n",
    "    else:\n",
    "        sentiment.append('negative')\n",
    "        sentiment_for_graph['neg']+=1\n",
    "file3 = pd.DataFrame({'Comments':comment_list,'Sentiment':sentiment})\n",
    "file3.to_csv('Comment.csv',index=False)\n",
    "\n",
    "total = sentiment_for_graph['pos'] + sentiment_for_graph['neg'] + sentiment_for_graph['neutral']\n",
    "pos_percent = sentiment_for_graph['pos']*100/total\n",
    "neg_percent = sentiment_for_graph['neg']*100/total\n",
    "neutral_percent = sentiment_for_graph['neutral']*100/total\n",
    "\n",
    "fig , (ax1,ax2) = plt.subplots(nrows=1, ncols=2,figsize =(10,5))\n",
    "# %matplotlib nbagg\n",
    "ax1.bar(sentiment_for_graph.keys(),sentiment_for_graph.values())\n",
    "ax1.set(title='Count-wise Bar plot')\n",
    "plt.style.use('seaborn')\n",
    "crs = mplcursors.cursor(ax1,hover=True)\n",
    "crs.connect(\"add\", lambda sel: sel.annotation.set_text('Total Count: {}'.format(sel.target[1])))\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "ss = {'pos':pos_percent,'neg':neg_percent,'neutral':neutral_percent}\n",
    "ax2.bar(ss.keys(),ss.values())\n",
    "ax2.set(title='Percent-wise Bar plot')\n",
    "crs = mplcursors.cursor(ax2,hover=True)\n",
    "crs.connect(\"add\", lambda sel: sel.annotation.set_text('Percentage: {}%'.format(sel.target[1])));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
